//Aiming at a target

Now that you have properly set up your vision system and have tuned a pipeline, you can now aim your robot at an AprilTag using the data from PhotonVision. The yaw of the target is the critical piece of data that will be needed first.

Yaw is reported to the roboRIO over Network Tables. PhotonLib, our vender dependency, is the easiest way to access this data. The documentation for the Network Tables API can be found here and the documentation for PhotonLib here.

In this example, while the operator holds a button down, the robot will turn towards the AprilTag using the P term of a PID loop. To learn more about how PID loops work, how WPILib implements them, and more, visit Advanced Controls (PID) and PID Control in WPILib.

@Override
public void teleopPeriodic() {
    // Calculate drivetrain commands from Joystick values
    double forward = -controller.getLeftY() * Constants.Swerve.kMaxLinearSpeed;
    double strafe = -controller.getLeftX() * Constants.Swerve.kMaxLinearSpeed;
    double turn = -controller.getRightX() * Constants.Swerve.kMaxAngularSpeed;

    // Read in relevant data from the Camera
    boolean targetVisible = false;
    double targetYaw = 0.0;
    var results = camera.getAllUnreadResults();
    if (!results.isEmpty()) {
        // Camera processed a new frame since last
        // Get the last one in the list.
        var result = results.get(results.size() - 1);
        if (result.hasTargets()) {
            // At least one AprilTag was seen by the camera
            for (var target : result.getTargets()) {
                if (target.getFiducialId() == 7) {
                    // Found Tag 7, record its information
                    targetYaw = target.getYaw();
                    targetVisible = true;
                }
            }
        }
    }

    // Auto-align when requested
    if (controller.getAButton() && targetVisible) {
        // Driver wants auto-alignment to tag 7
        // And, tag 7 is in sight, so we can turn toward it.
        // Override the driver's turn command with an automatic one that turns toward the tag.
        turn = -1.0 * targetYaw * VISION_TURN_kP * Constants.Swerve.kMaxAngularSpeed;
    }

    // Command drivetrain motors based on target speeds
    drivetrain.drive(forward, strafe, turn);

    // Put debug information to the dashboard
    SmartDashboard.putBoolean("Vision Target Visible", targetVisible);
}

//Combining Aiming and Getting in Range
Now that you know how to aim toward the AprilTag, let’s also drive the correct distance from the AprilTag.

To do this, we’ll use the pitch of the target in the camera image and trigonometry to figure out how far away the robot is from the AprilTag. Then, like before, we’ll use the P term of a PID controller to drive the robot to the correct distance.

  // Calculate drivetrain commands from Joystick values
  double forward = -controller.getLeftY() * Constants.Swerve.kMaxLinearSpeed;
  double strafe = -controller.getLeftX() * Constants.Swerve.kMaxLinearSpeed;
  double turn = -controller.getRightX() * Constants.Swerve.kMaxAngularSpeed;

  // Read in relevant data from the Camera
  boolean targetVisible = false;
  double targetYaw = 0.0;
  double targetRange = 0.0;
  var results = camera.getAllUnreadResults();
  if (!results.isEmpty()) {
      // Camera processed a new frame since last
      // Get the last one in the list.
      var result = results.get(results.size() - 1);
      if (result.hasTargets()) {
          // At least one AprilTag was seen by the camera
          for (var target : result.getTargets()) {
              if (target.getFiducialId() == 7) {
                  // Found Tag 7, record its information
                  targetYaw = target.getYaw();
                  targetRange =
                          PhotonUtils.calculateDistanceToTargetMeters(
                                  0.5, // Measured with a tape measure, or in CAD.
                                  1.435, // From 2024 game manual for ID 7
                                  Units.degreesToRadians(-30.0), // Measured with a protractor, or in CAD.
                                  Units.degreesToRadians(target.getPitch()));

                  targetVisible = true;
              }
          }
      }
  }

  // Auto-align when requested
  if (controller.getAButton() && targetVisible) {
      // Driver wants auto-alignment to tag 7
      // And, tag 7 is in sight, so we can turn toward it.
      // Override the driver's turn and fwd/rev command with an automatic one
      // That turns toward the tag, and gets the range right.
      turn =
              (VISION_DES_ANGLE_deg - targetYaw) * VISION_TURN_kP * Constants.Swerve.kMaxAngularSpeed;
      forward =
              (VISION_DES_RANGE_m - targetRange) * VISION_STRAFE_kP * Constants.Swerve.kMaxLinearSpeed;
  }

  // Command drivetrain motors based on target speeds
  drivetrain.drive(forward, strafe, turn);

  //Using WPILib Pose Estimation, Simulation, and PhotonVision Together
  This example demonstrates integration of swerve drive control, a basic swerve physics simulation, and PhotonLib’s simulated vision system functionality.
  Estimating Pose
The Drivetrain class includes functionality to fuse multiple sensor readings together (including PhotonVision) into a best-guess of the pose on the field.

Please reference the WPILib documentation on using the SwerveDrivePoseEstimator class.

We use the 2024 game’s AprilTag Locations: